{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\jayesh ahire\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\jayesh ahire\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\jayesh ahire\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jayesh ahire\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jayesh ahire\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jayesh ahire\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\JAYESH\n",
      "[nltk_data]     AHIRE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\" Hey there! I am Jayesh Ahire, currently pursuing my BTech in Mechanical Engineering at IIT Bombay. I am very fascinated by the problems solved using Machine Learning and Artificial Intelligence.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hey there! I am Jayesh Ahire, currently pursuing my BTech in Mechanical Engineering at IIT Bombay. I am very fascinated by the problems solved using Machine Learning and Artificial Intelligence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Tokenization\n",
    "## Sentence-->paragraphs\n",
    "from nltk.tokenize import sent_tokenize     #break down corpus into sentences in a form of list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Hey there!', 'I am Jayesh Ahire, currently pursuing my BTech in Mechanical Engineering at IIT Bombay.', 'I am very fascinated by the problems solved using Machine Learning and Artificial Intelligence.']\n"
     ]
    }
   ],
   "source": [
    "documents = sent_tokenize(corpus)           #separated using punctuation marks\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hey there!\n",
      "I am Jayesh Ahire, currently pursuing my BTech in Mechanical Engineering at IIT Bombay.\n",
      "I am very fascinated by the problems solved using Machine Learning and Artificial Intelligence.\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence)                     #Printing each element in the list in new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization \n",
    "## Paragraph-->words\n",
    "## sentence--->words\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey',\n",
       " 'there',\n",
       " '!',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Jayesh',\n",
       " 'Ahire',\n",
       " ',',\n",
       " 'currently',\n",
       " 'pursuing',\n",
       " 'my',\n",
       " 'BTech',\n",
       " 'in',\n",
       " 'Mechanical',\n",
       " 'Engineering',\n",
       " 'at',\n",
       " 'IIT',\n",
       " 'Bombay',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'very',\n",
       " 'fascinated',\n",
       " 'by',\n",
       " 'the',\n",
       " 'problems',\n",
       " 'solved',\n",
       " 'using',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'and',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " '.']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hey', 'there', '!']\n",
      "['I', 'am', 'Jayesh', 'Ahire', ',', 'currently', 'pursuing', 'my', 'BTech', 'in', 'Mechanical', 'Engineering', 'at', 'IIT', 'Bombay', '.']\n",
      "['I', 'am', 'very', 'fascinated', 'by', 'the', 'problems', 'solved', 'using', 'Machine', 'Learning', 'and', 'Artificial', 'Intelligence', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(word_tokenize(sentence))              #Considers split as Jayesh's -> \"Jayesh\", \"'s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey',\n",
       " 'there',\n",
       " '!',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Jayesh',\n",
       " 'Ahire',\n",
       " ',',\n",
       " 'currently',\n",
       " 'pursuing',\n",
       " 'my',\n",
       " 'BTech',\n",
       " 'in',\n",
       " 'Mechanical',\n",
       " 'Engineering',\n",
       " 'at',\n",
       " 'IIT',\n",
       " 'Bombay',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'very',\n",
       " 'fascinated',\n",
       " 'by',\n",
       " 'the',\n",
       " 'problems',\n",
       " 'solved',\n",
       " 'using',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'and',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " '.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)              #Punctuation marks are considered as separate words\n",
    "                                        #Considers split as Jayesh's -> \"Jayesh\", \"'\", \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer         #Smart tokenizer: Only last full stop is considered as separate word. Rest all fullstops are included in the last word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey',\n",
       " 'there',\n",
       " '!',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Jayesh',\n",
       " 'Ahire',\n",
       " ',',\n",
       " 'currently',\n",
       " 'pursuing',\n",
       " 'my',\n",
       " 'BTech',\n",
       " 'in',\n",
       " 'Mechanical',\n",
       " 'Engineering',\n",
       " 'at',\n",
       " 'IIT',\n",
       " 'Bombay.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'very',\n",
       " 'fascinated',\n",
       " 'by',\n",
       " 'the',\n",
       " 'problems',\n",
       " 'solved',\n",
       " 'using',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'and',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " '.']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
